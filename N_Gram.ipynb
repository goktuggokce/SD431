{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHCqDGN7JlmC",
        "outputId": "86a63fec-9dce-4995-d278-3fdc8af8aae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5Ei9wsbHfZ9"
      },
      "outputs": [],
      "source": [
        "def stopword_proccess(text):\n",
        "  words=[word.lower() for word in text.split(\" \") if word not in set(stopwords.words('turkish'))]\n",
        "  return words\n",
        "def generate_N_grams(text, ngram=1):\n",
        "  words = stopword_proccess(text)\n",
        "  print(\"Sentence after removing stopwords:\", words)\n",
        "  temp=zip(*[words[i:] for i in range(0, ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cumlesi = \"Bu cümle 2024'de oluşturulmuş bir test cümlesi olmakla birlikte n-gram testi için hazırlanmıştır. Test cümlesi çıkartılması gereken ve ile gibi stopwords'leri içermektedir.\"\n",
        "n_gram = 7\n",
        "stringler = generate_N_grams(test_cumlesi, n_gram)\n",
        "print(\"Liste:\" + str(stringler))\n",
        "temp = stringler.copy()\n",
        "j = 1\n",
        "for i in stringler:\n",
        "  print(j, f'\"{i}\"')\n",
        "  j+=1\n",
        "  temp.remove(i)\n",
        "print(f\"\\nÇıktı: {n_gram}-gram işleminin sonucunda toplamda: {len(stringler)} string oluşmuştur.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiMrvcgiJR55",
        "outputId": "06bb3350-481a-4863-a92a-654b689fad26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence after removing stopwords: ['bu', 'cümle', \"2024'de\", 'oluşturulmuş', 'bir', 'test', 'cümlesi', 'olmakla', 'birlikte', 'n-gram', 'testi', 'hazırlanmıştır.', 'test', 'cümlesi', 'çıkartılması', 'gereken', \"stopwords'leri\", 'içermektedir.']\n",
            "Liste:[\"bu cümle 2024'de oluşturulmuş bir test cümlesi\", \"cümle 2024'de oluşturulmuş bir test cümlesi olmakla\", \"2024'de oluşturulmuş bir test cümlesi olmakla birlikte\", 'oluşturulmuş bir test cümlesi olmakla birlikte n-gram', 'bir test cümlesi olmakla birlikte n-gram testi', 'test cümlesi olmakla birlikte n-gram testi hazırlanmıştır.', 'cümlesi olmakla birlikte n-gram testi hazırlanmıştır. test', 'olmakla birlikte n-gram testi hazırlanmıştır. test cümlesi', 'birlikte n-gram testi hazırlanmıştır. test cümlesi çıkartılması', 'n-gram testi hazırlanmıştır. test cümlesi çıkartılması gereken', \"testi hazırlanmıştır. test cümlesi çıkartılması gereken stopwords'leri\", \"hazırlanmıştır. test cümlesi çıkartılması gereken stopwords'leri içermektedir.\"]\n",
            "1 \"bu cümle 2024'de oluşturulmuş bir test cümlesi\"\n",
            "2 \"cümle 2024'de oluşturulmuş bir test cümlesi olmakla\"\n",
            "3 \"2024'de oluşturulmuş bir test cümlesi olmakla birlikte\"\n",
            "4 \"oluşturulmuş bir test cümlesi olmakla birlikte n-gram\"\n",
            "5 \"bir test cümlesi olmakla birlikte n-gram testi\"\n",
            "6 \"test cümlesi olmakla birlikte n-gram testi hazırlanmıştır.\"\n",
            "7 \"cümlesi olmakla birlikte n-gram testi hazırlanmıştır. test\"\n",
            "8 \"olmakla birlikte n-gram testi hazırlanmıştır. test cümlesi\"\n",
            "9 \"birlikte n-gram testi hazırlanmıştır. test cümlesi çıkartılması\"\n",
            "10 \"n-gram testi hazırlanmıştır. test cümlesi çıkartılması gereken\"\n",
            "11 \"testi hazırlanmıştır. test cümlesi çıkartılması gereken stopwords'leri\"\n",
            "12 \"hazırlanmıştır. test cümlesi çıkartılması gereken stopwords'leri içermektedir.\"\n",
            "\n",
            "Çıktı: 7-gram işleminin sonucunda toplamda: 12 string oluşmuştur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = defaultdict(lambda: defaultdict(int))\n",
        "stringler = generate_N_grams(test_cumlesi, 2)\n",
        "for s in stringler:\n",
        "    w1, w2 = s.split(\" \")\n",
        "    model[w1][w2] += 1\n",
        "\n",
        "frekans = model[\"test\"][\"cümlesi\"]\n",
        "print(f'2-gram olarak ayrılmış listede, \"test cümlesi\":', frekans, f\"kez geçmektedir.\\nOlasılıksal olarak: {frekans}/{len(stringler)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpcG6NdqMWi4",
        "outputId": "f79baf7e-1b3e-445b-e9c5-164907feafa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence after removing stopwords: ['bu', 'cümle', \"2024'de\", 'oluşturulmuş', 'bir', 'test', 'cümlesi', 'olmakla', 'birlikte', 'n-gram', 'testi', 'hazırlanmıştır.', 'test', 'cümlesi', 'çıkartılması', 'gereken', \"stopwords'leri\", 'içermektedir.']\n",
            "2-gram olarak ayrılmış listede, \"test cümlesi\": 2 kez geçmektedir.\n",
            "Olasılıksal olarak: 2/17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cumlesi_uzunlugu = len(stopword_proccess(test_cumlesi))\n",
        "k = 1\n",
        "print(\"Test Cümlesi:\", f'\"{test_cumlesi}\"', \"\\n\")\n",
        "while k <= test_cumlesi_uzunlugu:\n",
        "  print(f\"{k}-gram oluşacak kelime sayısı:\", test_cumlesi_uzunlugu-k+1)\n",
        "  k += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVPVYhzxcrZO",
        "outputId": "56adb3ed-e9b2-4037-fd2f-cd838d9c026d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Cümlesi: \"Bu cümle 2024'de oluşturulmuş bir test cümlesi olmakla birlikte n-gram testi için hazırlanmıştır. Test cümlesi çıkartılması gereken ve ile gibi stopwords'leri içermektedir.\" \n",
            "\n",
            "1-gram oluşacak kelime sayısı: 18\n",
            "2-gram oluşacak kelime sayısı: 17\n",
            "3-gram oluşacak kelime sayısı: 16\n",
            "4-gram oluşacak kelime sayısı: 15\n",
            "5-gram oluşacak kelime sayısı: 14\n",
            "6-gram oluşacak kelime sayısı: 13\n",
            "7-gram oluşacak kelime sayısı: 12\n",
            "8-gram oluşacak kelime sayısı: 11\n",
            "9-gram oluşacak kelime sayısı: 10\n",
            "10-gram oluşacak kelime sayısı: 9\n",
            "11-gram oluşacak kelime sayısı: 8\n",
            "12-gram oluşacak kelime sayısı: 7\n",
            "13-gram oluşacak kelime sayısı: 6\n",
            "14-gram oluşacak kelime sayısı: 5\n",
            "15-gram oluşacak kelime sayısı: 4\n",
            "16-gram oluşacak kelime sayısı: 3\n",
            "17-gram oluşacak kelime sayısı: 2\n",
            "18-gram oluşacak kelime sayısı: 1\n"
          ]
        }
      ]
    }
  ]
}